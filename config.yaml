# ── A2 Deutsch Grammar Tutor ── Model & Training Config ──

model:
  vocab_size: 4000 # V — curated word-level tokens (A2 forms + PDF words)
  max_seq_len: 64 # T — context window
  d_model: 128 # embedding / hidden dimension
  n_layers: 4 # L — decoder blocks
  n_heads: 4 # H — attention heads
  d_ff: 512 # FFN hidden dimension
  weight_tying: true # tie embeddings and LM head

training:
  batch_size: 64
  learning_rate: 3e-4
  epochs: 20
  warmup_steps: 500
  device: "mps" # "mps" for Mac M1/M2, "cuda" for NVIDIA, "cpu" for others

data:
  train_path: "data/train.jsonl"
  val_path: "data/val.jsonl"

generation:
  temperature: 0.7
  top_k: 50
