# üá©üá™ A2 Deutsch Grammar Tutor

–ö–æ–º–ø–∞–∫—Ç–Ω–∞ Transformer-–º–æ–¥–µ–ª—å –¥–ª—è –ø–µ—Ä–µ–≤—ñ—Ä–∫–∏ —Ç–∞ –ø–æ—è—Å–Ω–µ–Ω–Ω—è –ø–æ–º–∏–ª–æ–∫ —É –Ω—ñ–º–µ—Ü—å–∫–∏—Ö —Ä–µ—á–µ–Ω–Ω—è—Ö —Ä—ñ–≤–Ω—è A2. 
–ù–∞–≤—á–µ–Ω–∞ –≤–∏–ø—Ä–∞–≤–ª—è—Ç–∏ –≥—Ä–∞–º–∞—Ç–∏–∫—É —Ç–∞ –ø–æ—è—Å–Ω—é–≤–∞—Ç–∏ –ø—Ä–∞–≤–∏–ª–∞ —É–∫—Ä–∞—ó–Ω—Å—å–∫–æ—é –º–æ–≤–æ—é.

## –©–æ –≤–º—ñ—î –º–æ–¥–µ–ª—å

| –§—É–Ω–∫—Ü—ñ—è | –ü—Ä–∏–∫–ª–∞–¥ |
|---|---|
| ‚úÖ –í–∏–∑–Ω–∞—á–∞—î –ø—Ä–∞–≤–∏–ª—å–Ω—ñ—Å—Ç—å | `Ich bin nach Hause gegangen.` ‚Üí ‚úÖ |
| ‚ùå –í–∏–ø—Ä–∞–≤–ª—è—î –ø–æ–º–∏–ª–∫–∏ | `Dann —è gehe...` ‚Üí `Dann gehe ich...` |
| üìù –ü–æ—è—Å–Ω—é—î | –ü—Ä–∏—Å–ª—ñ–≤–Ω–∏–∫ –Ω–∞ –ø–æ—á–∞—Ç–∫—É –≤–∏–º–∞–≥–∞—î —ñ–Ω–≤–µ—Ä—Å—ñ—ó –ø—ñ–¥–º–µ—Ç–∞ |

### –ü–æ–∫—Ä–∏—Ç—ñ —Ç–µ–º–∏ A2

- **Perfekt** ‚Äî haben/sein + Partizip II
- **Word Order** ‚Äî —ñ–Ω–≤–µ—Ä—Å—ñ—è, –¥—ñ—î—Å–ª–æ–≤–æ –Ω–∞ 2-–º—É –º—ñ—Å—Ü—ñ
- **Dativ / Akkusativ** ‚Äî –∫–µ—Ä—É–≤–∞–Ω–Ω—è –¥—ñ—î—Å–ª—ñ–≤ —Ç–∞ –ø—Ä–∏–π–º–µ–Ω–Ω–∏–∫—ñ–≤
- **–ú–æ–¥–∞–ª—å–Ω—ñ –¥—ñ—î—Å–ª–æ–≤–∞** ‚Äî –≤—ñ–¥–º—ñ–Ω—é–≤–∞–Ω–Ω—è —Ç–∞ –ø–æ–∑–∏—Ü—ñ—è –≤ —Ä–µ—á–µ–Ω–Ω—ñ
- **–ó–∞–ø–µ—Ä–µ—á–µ–Ω–Ω—è** ‚Äî kein vs. nicht

## –ê—Ä—Ö—ñ—Ç–µ–∫—Ç—É—Ä–∞

```
Transformer Decoder Only
‚îú‚îÄ‚îÄ V = 4 000 —Ç–æ–∫–µ–Ω—ñ–≤ (—Å–ª–æ–≤–∞ + —Ñ–æ—Ä–º–∏ + —É–∫—Ä. –ø–æ—è—Å–Ω–µ–Ω–Ω—è)
‚îú‚îÄ‚îÄ T = 64  (–º–∞–∫—Å. –¥–æ–≤–∂–∏–Ω–∞ —Ä–µ—á–µ–Ω–Ω—è)
‚îú‚îÄ‚îÄ d_model = 128
‚îú‚îÄ‚îÄ L = 4 –±–ª–æ–∫–∏ (Layers)
‚îú‚îÄ‚îÄ H = 4 –≥–æ–ª–æ–≤–∏ (Attention Heads)
‚îú‚îÄ‚îÄ Weight tying = ON (—Å–ø—ñ–ª—å–Ω—ñ –≤–∞–≥–∏ Embeddings —Ç–∞ LM Head)
‚îî‚îÄ‚îÄ Precision = FP16 ‚Üí —Ä–æ–∑–º—ñ—Ä –º–æ–¥–µ–ª—ñ ‚âà 2.5 MB

–î–µ—Ç–∞–ª—å–Ω–∏–π –º–∞—Ç–µ–º–∞—Ç–∏—á–Ω–∏–π –æ–ø–∏—Å —É—Å—ñ—Ö –º–∞—Ç—Ä–∏—á–Ω–∏—Ö –ø–µ—Ä–µ—Ç–≤–æ—Ä–µ–Ω—å –¥–∏–≤–∏—Å—å —É [docs/architecture.md](docs/architecture.md).
```

## –°—Ç—Ä—É–∫—Ç—É—Ä–∞ –ø—Ä–æ—î–∫—Ç—É

```text
A2-Deutsch-Transformer/
‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îú‚îÄ‚îÄ tokenizer/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ build_vocab.py   # –°–∫—Ä–∏–ø—Ç –∞–Ω–∞–ª—ñ–∑—É PDF —Ç–∞ —Å—Ç–≤–æ—Ä–µ–Ω–Ω—è —Å–ª–æ–≤–Ω–∏–∫–∞
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ tokenizer.py     # Word-level —Ç–æ–∫–µ–Ω—ñ–∑–∞—Ç–æ—Ä
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ vocab.json       # –ì–æ—Ç–æ–≤–∏–π —Å–ª–æ–≤–Ω–∏–∫ (4000 —Å–ª—ñ–≤)
‚îÇ   ‚îú‚îÄ‚îÄ model/
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ model.py         # –ê—Ä—Ö—ñ—Ç–µ–∫—Ç—É—Ä–∞ –Ω–µ–π—Ä–æ–º–µ—Ä–µ–∂—ñ (PyTorch)
‚îÇ   ‚îú‚îÄ‚îÄ data/
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ generator.py     # –†–æ–∑—É–º–Ω–∏–π –≥–µ–Ω–µ—Ä–∞—Ç–æ—Ä —Å–∏–Ω—Ç–µ—Ç–∏—á–Ω–∏—Ö –ø–æ–º–∏–ª–æ–∫
‚îÇ   ‚îú‚îÄ‚îÄ train.py             # –°–∫—Ä–∏–ø—Ç –Ω–∞–≤—á–∞–Ω–Ω—è (–æ–ø—Ç–∏–º—ñ–∑–æ–≤–∞–Ω–æ –¥–ª—è MPS/M1)
‚îÇ   ‚îî‚îÄ‚îÄ generate.py          # –°–∫—Ä–∏–ø—Ç –¥–ª—è —Ç–µ—Å—Ç—É–≤–∞–Ω–Ω—è –º–æ–¥–µ–ª—ñ
‚îú‚îÄ‚îÄ data/                    # –ó–≥–µ–Ω–µ—Ä–æ–≤–∞–Ω—ñ –¥–∞—Ç–∞—Å–µ—Ç–∏ (JSONL)
‚îú‚îÄ‚îÄ data_raw/                # –°–∏—Ä—ñ –¥–∞–Ω—ñ (PDF –ø—ñ–¥—Ä—É—á–Ω–∏–∫–∏)
‚îú‚îÄ‚îÄ config.yaml              # –ì–ª–æ–±–∞–ª—å–Ω—ñ –Ω–∞–ª–∞—à—Ç—É–≤–∞–Ω–Ω—è
‚îî‚îÄ‚îÄ requirements.txt
```

## –Ø–∫ —Ü–µ –ø—Ä–∞—Ü—é—î

### 1. `build_vocab.py`
–°—Ç–≤–æ—Ä—é—î "–º–æ–∑–æ–∫" —Ç–æ–∫–µ–Ω—ñ–∑–∞—Ç–æ—Ä–∞. –í—ñ–Ω –∞–Ω–∞–ª—ñ–∑—É—î –ø—ñ–¥—Ä—É—á–Ω–∏–∫ `Begegnungen_A2.pdf`, –≤–∏—Ç—è–≥—É—î –Ω–∞–π—á–∞—Å—Ç—ñ—à—ñ –Ω—ñ–º–µ—Ü—å–∫—ñ —Å–ª–æ–≤–∞, –¥–æ–¥–∞—î –¥–æ –Ω–∏—Ö —Ç–∞–±–ª–∏—Ü—ñ –≤—ñ–¥–º—ñ–Ω—é–≤–∞–Ω–Ω—è –¥—ñ—î—Å–ª—ñ–≤ —Ç–∞ —É–∫—Ä–∞—ó–Ω—Å—å–∫—ñ —Å–ª–æ–≤–∞ –¥–ª—è –ø–æ—è—Å–Ω–µ–Ω—å. –†–µ–∑—É–ª—å—Ç–∞—Ç ‚Äî —Ñ–∞–π–ª `vocab.json` –Ω–∞ 4000 —É–Ω—ñ–∫–∞–ª—å–Ω–∏—Ö —Ç–æ–∫–µ–Ω—ñ–≤.

### 2. `generator.py`
–°—Ç–≤–æ—Ä—é—î —Ç–∏—Å—è—á—ñ –ø—Ä–∏–∫–ª–∞–¥—ñ–≤ –¥–ª—è –Ω–∞–≤—á–∞–Ω–Ω—è. –í—ñ–Ω –∑–Ω–∞—î –ø—Ä–∞–≤–∏–ª–∞ –≥—Ä–∞–º–∞—Ç–∏–∫–∏, –±–µ—Ä–µ –ø—Ä–∞–≤–∏–ª—å–Ω–µ —Ä–µ—á–µ–Ω–Ω—è —ñ –Ω–∞–≤–º–∏—Å–Ω–æ "–ª–∞–º–∞—î" –π–æ–≥–æ (–Ω–∞–ø—Ä–∏–∫–ª–∞–¥, –º—ñ–Ω—è—î –ø–æ—Ä—è–¥–æ–∫ —Å–ª—ñ–≤ –∞–±–æ –¥–æ–ø–æ–º—ñ–∂–Ω–µ –¥—ñ—î—Å–ª–æ–≤–æ), –¥–æ–¥–∞—é—á–∏ –ø–æ—è—Å–Ω–µ–Ω–Ω—è, —á–æ–º—É —Ü–µ –ø–æ–º–∏–ª–∫–∞.

### 3. –ù–∞–≤—á–∞–Ω–Ω—è
–ú–æ–¥–µ–ª—å —Ç—Ä–µ–Ω—É—î—Ç—å—Å—è –ª–æ–∫–∞–ª—å–Ω–æ –Ω–∞ **Apple Silicon (M1/M2/M3)** –∑–∞ –¥–æ–ø–æ–º–æ–≥–æ—é `torch.device("mps")`. –ó–∞–≤–¥—è–∫–∏ –º–∞–ª–µ–Ω—å–∫–æ–º—É —Ä–æ–∑–º—ñ—Ä—É (2.5 –ú–ë), –Ω–∞–≤—á–∞–Ω–Ω—è –∑–∞–π–º–∞—î –ª—ñ—á–µ–Ω—ñ —Ö–≤–∏–ª–∏–Ω–∏.

## –®–≤–∏–¥–∫–∏–π —Å—Ç–∞—Ä—Ç

```bash
# 1. –í—Å—Ç–∞–Ω–æ–≤–∏—Ç–∏ –∑–∞–ª–µ–∂–Ω–æ—Å—Ç—ñ
pip install -r requirements.txt

# 2. –°—Ç–≤–æ—Ä–∏—Ç–∏ —Å–ª–æ–≤–Ω–∏–∫ (—è–∫—â–æ –∑–º—ñ–Ω–∏–ª–∏ —Å–ø–∏—Å–∫–∏ —Å–ª—ñ–≤)
python src/tokenizer/build_vocab.py

# 3. –ó–≥–µ–Ω–µ—Ä—É–≤–∞—Ç–∏ –¥–∞–Ω—ñ (5000+ –ø—Ä–∏–∫–ª–∞–¥—ñ–≤)
python src/data/generator.py

# 4. –ó–∞–ø—É—Å—Ç–∏—Ç–∏ –Ω–∞–≤—á–∞–Ω–Ω—è
python src/train.py

# 5. –ü–µ—Ä–µ–≤—ñ—Ä–∏—Ç–∏ —Ä–µ—á–µ–Ω–Ω—è
python src/generate.py --text "Ich habe nach Berlin gefahren."
```

## –§–æ—Ä–º–∞—Ç –¥–∞–Ω–∏—Ö (JSONL)

```json
{
  "input": "Heute ich gehe ins Kino.",
  "output": "‚ùå Incorrect.\n‚úÖ Correct: Heute gehe ich ins Kino.\nüìù –ü–æ—è—Å–Ω–µ–Ω–Ω—è: –î—ñ—î—Å–ª–æ–≤–æ –º–∞—î —Å—Ç–æ—è—Ç–∏ –Ω–∞ –¥—Ä—É–≥–æ–º—É –º—ñ—Å—Ü—ñ."
}
```

## –õ—ñ—Ü–µ–Ω–∑—ñ—è

MIT
